{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dealing_with_data_online_algorithm.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VsGBvYtQfuZj","slideshow":{"slide_type":"slide"}},"source":["# <center> Dealing With Data </center>\n","## <center> Linear Separatrix -   Making it online  </center>\n","### <center> Prof. Laxmidhar Behera </center>\n","### <center> IIT Kanpur </center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UuCN4ymyhVQp","slideshow":{"slide_type":"slide"}},"source":["\n","\n","- Given data and linear model, data can be represented in terms of the following expression - <br>\n","$Aw = y$ &nbsp; $A \\in R^{1\\times n}$ &nbsp; $w \\in R^{n\\times m}$ &nbsp; $y \\in R^{1\\times m}$ <br><br>\n","- The methods like least square solution and minimum norm solution are generally offline techniques.\n","-   To learn the unknown parameters in an online way , i.e., to update $w$ as we see the new data, we define a cost or loss function and then minimize it using an algorithm called gradient descent.\n","- **Cost(or Loss) function**:\n","It is a function of the difference between estimated and true values for an instance of data.-<br>\n","<center>$E = \\frac{1}{2} \\sum_{i=1}^m (y_i^d - y_i)^2$<br></center>\n","  where $y_i^d$ is the desired $i^{th}$output and $y_i$ is the calculated $i^{th}$ output for a single data point. \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ueXQ0bw2wwtA","slideshow":{"slide_type":"slide"}},"source":["- To minimize this loss function, we use a method called <b> Gradient Descent</b> \n","\n","\n","## <center>  Gradient Descent  </center>\n","- In this , we update the unknown parameters iteratively for finding the minimum of a function .\n","-  In this algorithm, we first compute the slope or gradient of the function at the current point.\n","- The algorithm then takes steps in the direction opposite to the direction of the gradient at the current point.\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1z3HXUPpzx8fTjkYXf9i9sxTQidE-C6Wx\" alt=\"Drawing\" style=\"width: 200px;\"/>\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"a1CHdIGFItTZ","slideshow":{"slide_type":"slide"}},"source":["### <center>Loading Data in python</center>\n","Sklearn.datasets  is a library of many standard datasets including iris data <br>\n","Numpy is a numerical processing library in python <br>\n","Keras is a python library for building deep neural networks"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HSoIps3TPkkE","colab":{}},"source":["from sklearn.datasets import load_iris\n","import numpy as np\n","\n","np.random.seed(10) # For random weight initialization\n","\n","iris = load_iris() # iris is a python dictionary with key-value pairs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zTbdPqu2I3Bh","slideshow":{"slide_type":"slide"}},"source":["#### Pre-process Data\n","Convert labels to categorical - One-hot encoding"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6FbnHxSfPp_i","outputId":"86b1b0c1-e00b-44b5-b415-af77d0fad3d0","executionInfo":{"status":"ok","timestamp":1559821475415,"user_tz":-330,"elapsed":3038,"user":{"displayName":"Sai Saurab","photoUrl":"","userId":"06528725485567637895"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X = iris['data']\n","Y = iris['target']\n","from keras.utils import to_categorical\n","\n","Ny = len(np.unique(Y)) # Ny is number of categories/classes\n","\n","\n","Y = to_categorical(Y[:], num_classes = Ny) # "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ka3K4QbUI-7k","slideshow":{"slide_type":"slide"}},"source":["#### Train - Test split\n","#### Data Normalization/Scaling"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UkcAwMTcP5A7","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 1)\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","scaler.fit(X_train) # Computes the mean and standard deviation\n","\n","X_train = scaler.transform(X_train) # Perform transformation: x = (x-mean)/std\n","X_test = scaler.transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1-EoOFlGQNL2","slideshow":{"slide_type":"slide"},"colab":{}},"source":["# define function to add column of 1's\n","addlcol = lambda x: np.concatenate((x, np.ones((x.shape[0], 1))), axis = 1)\n","A = addlcol(X_train)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ha6Ru8G3N1Ts","outputId":"60b79a2c-8e0b-46f5-bdc4-dfeaddcec297","executionInfo":{"status":"ok","timestamp":1559821475424,"user_tz":-330,"elapsed":3023,"user":{"displayName":"Sai Saurab","photoUrl":"","userId":"06528725485567637895"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["A.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(120, 5)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t31lCCjmLExW","slideshow":{"slide_type":"slide"}},"source":["# Weight update using gradient descent\n","\n","\n","\n","### $w_{new} = w_{old} - \\eta \\ \\frac{\\partial E}{\\partial w} $\n","\n","### $E = \\frac{1}{2} \\sum_{j=1}^3 (y_j^d - y_j)^2$\n","\n","### ${\\frac{\\partial E}{\\partial w}}_{5\\times3} = - \\sum_{j=1}^3 (y_j^d - y_j) A = - A^T_{5\\times1} e_{1\\times3}  $\n","\n","### $w_{new} = w_{old} + \\eta A^T e \\ \\ \\ \\ \\ \\ \\ \\ (1)$\n","\n","### Algorithm\n","\n","- Initialize random weights between (-0.5 , 0.5)\n","\n","For each sample, \n","- First calculate y = Aw \n","- Find error(e) = $y^d - y$\n","- Update weights using (1).\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z5P07QvlSZZ7","slideshow":{"slide_type":"slide"},"outputId":"20802de7-1d5e-4754-da1a-ee6e830e2310","executionInfo":{"status":"ok","timestamp":1559817081561,"user_tz":-330,"elapsed":3230,"user":{"displayName":"sachin kumar sahoo","photoUrl":"https://lh3.googleusercontent.com/-d5Na2Cmv7Us/AAAAAAAAAAI/AAAAAAAAAbE/BuiMQpBwiKA/s64/photo.jpg","userId":"04645023824496771729"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["w = (2*np.random.rand(5,3) - 1)/2\n","\n","eta = 0.06\n","for i in range(A.shape[0]):\n","  y = (A[i].reshape(1,5)).dot(w)\n","  yd = Y_train[i]\n","  e = yd-y\n","  w = w + eta*(A[i].reshape(5,1)).dot(e.reshape(1,3))\n","  \n","print('weights are \\n', w)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["weights are \n"," [[ 0.11000672 -0.09270634  0.07104678]\n"," [ 0.10879821 -0.19875927  0.04753876]\n"," [-0.27045262  0.20677142 -0.23675619]\n"," [-0.20867913 -0.14909211  0.55711492]\n"," [ 0.30148813  0.34708777  0.35471917]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eHY14HVebavY","outputId":"68a4f80f-1f83-4949-ba0a-0d1b33c746aa","slideshow":{"slide_type":"slide"},"executionInfo":{"status":"ok","timestamp":1559817081563,"user_tz":-330,"elapsed":3228,"user":{"displayName":"sachin kumar sahoo","photoUrl":"https://lh3.googleusercontent.com/-d5Na2Cmv7Us/AAAAAAAAAAI/AAAAAAAAAbE/BuiMQpBwiKA/s64/photo.jpg","userId":"04645023824496771729"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["def evaluate(X, W, Yd, transform_X_a):\n","  a = transform_X_a(X)\n","  yd = np.argmax(Yd, axis = 1)\n","  y = np.argmax(a.dot(W), axis = 1)\n","  print('Confusion Matrix:')\n","  print(confusion_matrix(yd, y))\n","\n","\n","evaluate(X_train, w, Y_train, addlcol)\n","evaluate(X_test, w, Y_test, addlcol)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","[[38  1  0]\n"," [ 0 27 10]\n"," [ 0  5 39]]\n","Confusion Matrix:\n","[[11  0  0]\n"," [ 0  7  6]\n"," [ 0  0  6]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"s8WongYWJ3aa","slideshow":{"slide_type":"slide"}},"source":["# Second Model\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kycdY4aZJgUg"},"source":["<table>\n","  <tr>\n","    <th colspan=\"0\">X</th>\n","      <th colspan=\"4\">Y</th>\n","      <th colspan=\"6\"></th>\n","      </tr> \n","  <tr>\n","      <td>0.31</td><td>-0.04</td><td>0.45</td><td>0.23</td><td>0</td><td>1</td><td>0</td>\n","    </tr>\n","    <tr>\n","      <td>2.24</td><td>-0.46</td><td>1.30</td><td>1.40</td><td>0</td><td>0</td><td>1</td>\n","      </tr>\n","</table>\n","\\begin{align}\n","[l_s\\: b_s\\: l_p\\: b_p\\: l_s^2\\: b_s^2\\: l_p^2\\: b_p^2\\: 1] \\begin{bmatrix}\n","          w_{00} &w_{01} &w_{02}\\\\\n","          w_{10} &w_{11} &w_{12}\\\\\n","          \\vdots &\\vdots &\\vdots \\\\\n","          w_{80} &w_{81} &w_{82}\n","         \\end{bmatrix} = [y_0\\: y_1\\: y_2]\n","\\end{align}\n","<br><br>\n","<center>Aw = y</center>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"45VmohB0bQ1N","outputId":"47c02f77-c3d1-4c28-b8ad-27b7811be246","slideshow":{"slide_type":"slide"},"executionInfo":{"status":"ok","timestamp":1559817081567,"user_tz":-330,"elapsed":3228,"user":{"displayName":"sachin kumar sahoo","photoUrl":"https://lh3.googleusercontent.com/-d5Na2Cmv7Us/AAAAAAAAAAI/AAAAAAAAAbE/BuiMQpBwiKA/s64/photo.jpg","userId":"04645023824496771729"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["addSqlcol = lambda x: np.concatenate((x, x**2, np.ones((x.shape[0], 1))), axis = 1)\n","\n","A = addSqlcol(X_train)\n","Y = Y_train\n","\n","A.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(120, 9)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XqNogAVMmvS7","outputId":"145bda2f-c19b-4665-b1b7-0fc88c636ccf","slideshow":{"slide_type":"slide"},"executionInfo":{"status":"ok","timestamp":1559817081570,"user_tz":-330,"elapsed":3228,"user":{"displayName":"sachin kumar sahoo","photoUrl":"https://lh3.googleusercontent.com/-d5Na2Cmv7Us/AAAAAAAAAAI/AAAAAAAAAbE/BuiMQpBwiKA/s64/photo.jpg","userId":"04645023824496771729"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["eta = 0.05\n","w = (2*np.random.rand(9,3) - 1)/2\n","\n","\n","for i in range(A.shape[0]):\n","  y = (A[i].reshape(1,9)).dot(w)\n","  yd = Y_train[i]\n","  e = yd-y\n","  w = w + eta*(A[i].reshape(9,1)).dot(e.reshape(1,3))\n","\n","\n","evaluate(X_train, w, Y_train, addSqlcol)\n","evaluate(X_test, w, Y_test, addSqlcol)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","[[39  0  0]\n"," [ 0 34  3]\n"," [ 0  4 40]]\n","Confusion Matrix:\n","[[11  0  0]\n"," [ 0  8  5]\n"," [ 0  1  5]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HXxNp0yZqIqS","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}