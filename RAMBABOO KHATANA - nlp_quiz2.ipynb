{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RAMBABOO KHATANA - nlp_quiz2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WKIPkrmmUIuh"},"source":["##  Softmax\n","Write softmax to convert vectors into probability distribution <br>\n","1) All the elements of probability distribution should be positive. <br>\n","2) Sum of all the elements of distribution will be 1. <br>\n","\n","$Softmax(x_i) = \n","\\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"btXWSnSzUSwL","nbgrader":{"checksum":"28a5e10245b99b8ab2b48da1294931ce","grade":false,"grade_id":"cell-4294a66554d00ee0","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["import math\n","import numpy as np\n","def softmax(vector):\n","  \"\"\"\n","  Input : \n","      vector: np array of floats\n","  Output:\n","      distribution: np array of floats of same size as that of input converted by using softmax\n","  \"\"\"\n","  # YOUR CODE HERE\n","  x=vector\n","  distribution = np.exp(x)/np.sum(np.exp(x))\n","  return distribution  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"jgSQYlhoUYqm","nbgrader":{"checksum":"8ff6ce9c264971c4fcbae23ee8ee2801","grade":true,"grade_id":"cell-17756755bdef637a","locked":true,"points":2,"schema_version":1,"solution":false},"colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"bfa8e716-69a9-4dad-bfa0-dd424bf98c6a","executionInfo":{"status":"ok","timestamp":1561176871625,"user_tz":-330,"elapsed":1311,"user":{"displayName":"RAMBABOO KHATANA","photoUrl":"https://lh3.googleusercontent.com/-0IXPx9Ls1os/AAAAAAAAAAI/AAAAAAAADiE/9PU1ewkY8aU/s64/photo.jpg","userId":"03903798107742440375"}}},"source":["vector=np.array([1,2,3,4])\n","softmax(vector)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.0320586 , 0.08714432, 0.23688282, 0.64391426])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZxZ2s-atUbGD"},"source":["### Convert to One hot\n","Given a vector containing a probability distribution, convert it to one-hot vector with the max index having 1 and rest of the indices having 0"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"nXonICNLUtHI","nbgrader":{"checksum":"f5705ac653b727a1382d43c8b0316aad","grade":false,"grade_id":"cell-ba97ad83ad5b99e6","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["def convert_to_one_hot(p):\n","  \"\"\"\n","  Inputs:\n","    p: numpy array of 1 dimension, probability distribution\n","  Outputs:\n","    oh: one_hot vector corresponding to p\n","  \"\"\"\n","  # YOUR CODE HERE\n","  oh =np.zeros(len(p))\n","  m=max(p)\n","  oh[p.index(m)]=1\n","  return oh"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"c2ZuIvAdVNCK","nbgrader":{"checksum":"92856f376c2458b0ef41c939ae27f397","grade":true,"grade_id":"cell-dae6f55da8097488","locked":true,"points":2,"schema_version":1,"solution":false},"colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b5589fb8-1144-4346-cf3f-8ca707f13a14","executionInfo":{"status":"ok","timestamp":1561178193494,"user_tz":-330,"elapsed":960,"user":{"displayName":"RAMBABOO KHATANA","photoUrl":"https://lh3.googleusercontent.com/-0IXPx9Ls1os/AAAAAAAAAAI/AAAAAAAADiE/9PU1ewkY8aU/s64/photo.jpg","userId":"03903798107742440375"}}},"source":["convert_to_one_hot([1,2,3])"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 1.])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4ZXt3L4zVk2l"},"source":["## Complete analogy \n","\n","**Cosine Similarity:**\n","We can find the similarity in terms of  angle between two vectors. Formally, the Cosine Similarity  is  between two vectors  p  and  q  is defined as:\n","\n","$s = \\frac{p⋅q}{||p||||q||} $, where s∈[−1,1]<br>\n","Implement the function"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"5o7TWJYDVk48","nbgrader":{"checksum":"057c75e1bb9747b6827147dd16add597","grade":false,"grade_id":"cell-c710883418fe64f9","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["import math\n","import numpy as np\n","def cosine_similarity(v1,v2):\n","    \"\"\"\n","    Input:\n","        v1: numpy array \n","        v2: numpy array\n","        \n","    Output:\n","        v: single floating point value\n","        \n","        v = cosine similarity between v1 and v2 = (v1 dot v2)/{||v1||*||v2||}\n","    \"\"\"\n","    # YOUR CODE HERE\n","    v=(v1.dot(v2))/np.linalg.norm(v1,2)*np.linalg.norm(v2,2)\n","    return v"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"IBRXJTiVVk7F","nbgrader":{"checksum":"ca10ad33f541472c8e6e4ba85c99f401","grade":true,"grade_id":"cell-1ddefb3eb9ea742f","locked":true,"points":3,"schema_version":1,"solution":false},"colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"07ba58f1-0144-4b27-f5e8-b71433618b03","executionInfo":{"status":"ok","timestamp":1561177263807,"user_tz":-330,"elapsed":922,"user":{"displayName":"RAMBABOO KHATANA","photoUrl":"https://lh3.googleusercontent.com/-0IXPx9Ls1os/AAAAAAAAAAI/AAAAAAAADiE/9PU1ewkY8aU/s64/photo.jpg","userId":"03903798107742440375"}}},"source":["v1,v2=np.array([1,0]),np.array([0,1])\n","cosine_similarity(v1,v2)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ayLS2H-LVk89"},"source":["Consider the words $a, b, c, d$ and their corresponding word vectors $x_a, x_b, x_c, x_d$ such that they have this analogical relationship\n","$a:b :: c:d$ <br>\n","For eg.,<br>\n","Princess: Queen : : Prince : ? <br>\n","Complete the analogy by finding the missing word. <br>\n","To find out missing word \"d\", you need to find the word vector which has maximum cosine similarity with the vector $x_b - x_a + x_c$. The word corresponding to this vector is the word that will complete the analogy. In other words, you need to implment the following function <br>\n","$d = argmax_{x_i \\in \\mathcal{X}} \\frac{(x_b-x_a+x_c)^Tx_i}{||x_b-x_a+x_c||\\cdot ||x_i||}$\n"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"caAFxm09V2bE","nbgrader":{"checksum":"73bfd294eacef5166359054db16e971d","grade":false,"grade_id":"cell-9e2fdcaab9a983a6","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["def complete_analogy(a, b, c, word_dict):\n","  \"\"\"\n","  Inputs:\n","    a, b, c: strings, with analogical relationship as described above\n","    word_dict: dictionary, dictionary with keys as words and values as corresponding word vectors\n","  Output:\n","      missing: str, the missing word d\n","  \"\"\"\n","  # YOUR CODE HERE\n","  d=((a-b+c).T.dot(word_dict.values(x)))/np.linalg.norm((a-b+c),2)*np.linalg.norm((word_dict.values(x)),2)\n","  print(d)\n","  return d\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"2kwj81EHV3pz","nbgrader":{"checksum":"76ebd769ce21a3f481e4d29a8bdd687e","grade":true,"grade_id":"cell-63c4d958a4192123","locked":true,"points":3,"schema_version":1,"solution":false},"colab":{}},"source":["word_dict = {'princess':\t[-1.720603,\t-3.560657],\n","             'queen':\t[-0.722603,\t-1.232549],\n","\t           'girl':\t[-2.789075,\t-3.869762],\n","             'king':\t[-0.370373,\t0.576843],\n","            'prince':\t[-1.693504,\t0.719822],\n","            'toy':\t[2.78,\t-0.71],\n","            'lady':\t[-1.693,\t-0.7192],\n","            'student':\t[-1.693504,\t0.719822]}\n","\n","'''test for complete_analogy'''\n","def test_complete_analogy():\n","  test_complete_analogy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0x9YFr3cj65","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}